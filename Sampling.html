

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Sampling &mdash; costcla  documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="costcla  documentation" href="index.html"/>
        <link rel="next" title="Change Log" href="changelog.html"/>
        <link rel="prev" title="Probcal" href="Probcal.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        

        
          <a href="index.html" class="icon icon-home"> costcla
        

        
        </a>

        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="Metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="Models.html">Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="BayesMinimumRiskClassifier.html">BayesMinimumRiskClassifier</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ThresholdingOptimization.html">ThresholdingOptimization</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CostSensitiveLogisticRegression.html">CostSensitiveLogisticRegression</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CostSensitiveDecisionTreeClassifier.html">CostSensitiveDecisionTreeClassifier</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CostSensitiveRandomForestClassifier.html">CostSensitiveRandomForestClassifier</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CostSensitiveBaggingClassifier.html">CostSensitiveBaggingClassifier</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CostSensitivePastingClassifier.html">CostSensitivePastingClassifier</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CostSensitiveRandomPatchesClassifier.html">CostSensitiveRandomPatchesClassifier</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Probcal.html">Probcal</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Change Log</a><ul>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#version-0-04-tbd">Version 0.04 <em>TBD</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#version-0-03-2014-09-19">Version 0.03 <em>(2014-09-19)</em></a></li>
</ul>
</li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">costcla</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Sampling</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/Sampling.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
  <div class="section" id="module-costcla.sampling">
<span id="sampling"></span><h1>Sampling<a class="headerlink" href="#module-costcla.sampling" title="Permalink to this headline">¶</a></h1>
<p>The <a class="reference internal" href="#module-costcla.sampling" title="costcla.sampling"><code class="xref py py-mod docutils literal"><span class="pre">costcla.sampling</span></code></a> module includes methods for cost-sensitive sampling</p>
<p>In particular:</p>
<ul class="simple">
<li><a class="reference internal" href="#costcla.sampling.cost_sampling" title="costcla.sampling.cost_sampling"><code class="xref py py-mod docutils literal"><span class="pre">costcla.sampling.cost_sampling</span></code></a> methods for cost-proportionate sampling</li>
<li><a class="reference internal" href="#costcla.sampling.undersampling" title="costcla.sampling.undersampling"><code class="xref py py-mod docutils literal"><span class="pre">costcla.sampling.undersampling</span></code></a> traditional undersampling</li>
<li><a class="reference internal" href="#costcla.sampling.smote" title="costcla.sampling.smote"><code class="xref py py-mod docutils literal"><span class="pre">costcla.sampling.smote</span></code></a> SMOTE method for synthetic over-sampling</li>
</ul>
<dl class="function">
<dt id="costcla.sampling.cost_sampling">
<code class="descclassname">costcla.sampling.</code><code class="descname">cost_sampling</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>cost_mat</em>, <em>method='RejectionSampling'</em>, <em>oversampling_norm=0.1</em>, <em>max_wc=97.5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/costcla/sampling/cost_sampling.html#cost_sampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#costcla.sampling.cost_sampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Cost-proportionate sampling.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of shape = [n_samples, n_features]</p>
<blockquote class="last">
<div><blockquote>
<div><p>The input samples.</p>
</div></blockquote>
<dl class="docutils">
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd><p class="first last">Ground truth (correct) labels.</p>
</dd>
<dt>cost_mat <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples, 4]</span></dt>
<dd><p class="first last">Cost matrix of the classification problem
Where the columns represents the costs of: false positives, false negatives,
true positives and true negatives, for each example.</p>
</dd>
<dt>method <span class="classifier-delimiter">:</span> <span class="classifier">str, optional (default = RejectionSampling)</span></dt>
<dd><p class="first last">Method to perform the cost-proportionate sampling,
either &#8216;RejectionSampling&#8217; or &#8216;OverSampling&#8217;.</p>
</dd>
<dt>oversampling_norm: float, optional (default = 0.1)</dt>
<dd><p class="first last">normalize value of wc, the smaller the biggest the data.</p>
</dd>
<dt>max_wc: float, optional (default = 97.5)</dt>
<dd><p class="first last">outlier adjustment for the cost.</p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r15" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[R15]</a></td><td>B. Zadrozny, J. Langford, N. Naoki, &#8220;Cost-sensitive learning by
cost-proportionate example weighting&#8221;, in Proceedings of the
Third IEEE International Conference on Data Mining, 435-442, 2003.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r16" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[R16]</a></td><td>C. Elkan, &#8220;The foundations of Cost-Sensitive Learning&#8221;,
in Seventeenth International Joint Conference on Artificial Intelligence,
973-978, 2001.</td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">costcla.datasets</span> <span class="kn">import</span> <span class="n">load_creditscoring1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">costcla.sampling</span> <span class="kn">import</span> <span class="n">cost_sampling</span><span class="p">,</span> <span class="n">undersampling</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">costcla.metrics</span> <span class="kn">import</span> <span class="n">savings_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_creditscoring1</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sets</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">cost_mat</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">cost_mat_train</span><span class="p">,</span> <span class="n">cost_mat_test</span> <span class="o">=</span> <span class="n">sets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_cps_o</span><span class="p">,</span> <span class="n">y_cps_o</span><span class="p">,</span> <span class="n">cost_mat_cps_o</span> <span class="o">=</span>  <span class="n">cost_sampling</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cost_mat_train</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&#39;OverSampling&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_cps_r</span><span class="p">,</span> <span class="n">y_cps_r</span><span class="p">,</span> <span class="n">cost_mat_cps_r</span> <span class="o">=</span>  <span class="n">cost_sampling</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cost_mat_train</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&#39;RejectionSampling&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_u</span><span class="p">,</span> <span class="n">y_u</span><span class="p">,</span> <span class="n">cost_mat_u</span> <span class="o">=</span> <span class="n">undersampling</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cost_mat_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred_test_rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred_test_rf_cps_o</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cps_o</span><span class="p">,</span> <span class="n">y_cps_o</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred_test_rf_cps_r</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cps_r</span><span class="p">,</span> <span class="n">y_cps_r</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred_test_rf_u</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_u</span><span class="p">,</span> <span class="n">y_u</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Savings using only RandomForest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">savings_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test_rf</span><span class="p">,</span> <span class="n">cost_mat_test</span><span class="p">)</span>
<span class="go">0.12454256594</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Savings using RandomForest with cost-proportionate over-sampling</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">savings_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test_rf_cps_o</span><span class="p">,</span> <span class="n">cost_mat_test</span><span class="p">)</span>
<span class="go">0.192480226286</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Savings using RandomForest with cost-proportionate rejection-sampling</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">savings_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test_rf_cps_r</span><span class="p">,</span> <span class="n">cost_mat_test</span><span class="p">)</span>
<span class="go">0.465830173459</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Savings using RandomForest with under-sampling</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">savings_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test_rf_u</span><span class="p">,</span> <span class="n">cost_mat_test</span><span class="p">)</span>
<span class="go">0.466630646543</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Size of each training set</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_cps_o</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_cps_r</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_u</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">75653 109975 8690 10191</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Percentage of positives in each training set</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">y_cps_o</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">y_cps_r</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">y_u</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="go">0.0668182358928 0.358054103205 0.436939010357 0.49602590521</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="costcla.sampling.undersampling">
<code class="descclassname">costcla.sampling.</code><code class="descname">undersampling</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>cost_mat=None</em>, <em>per=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/costcla/sampling/sampling.html#undersampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#costcla.sampling.undersampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Under-sampling.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of shape = [n_samples, n_features]</p>
<blockquote class="last">
<div><blockquote>
<div><p>The input samples.</p>
</div></blockquote>
<dl class="docutils">
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd><p class="first last">Ground truth (correct) labels.</p>
</dd>
<dt>cost_mat <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples, 4], optional (default=None)</span></dt>
<dd><p class="first last">Cost matrix of the classification problem
Where the columns represents the costs of: false positives, false negatives,
true positives and true negatives, for each example.</p>
</dd>
<dt>per: float, optional (default = 0.5)</dt>
<dd><p class="first last">Percentage of the minority class in the under-sampled data</p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="costcla.sampling.smote">
<code class="descclassname">costcla.sampling.</code><code class="descname">smote</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>cost_mat=None</em>, <em>per=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/costcla/sampling/sampling.html#smote"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#costcla.sampling.smote" title="Permalink to this definition">¶</a></dt>
<dd><p>SMOTE: synthetic minority over-sampling technique</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of shape = [n_samples, n_features]</p>
<blockquote class="last">
<div><blockquote>
<div><p>The input samples.</p>
</div></blockquote>
<dl class="docutils">
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd><p class="first last">Ground truth (correct) labels.</p>
</dd>
<dt>cost_mat <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples, 4], optional (default=None)</span></dt>
<dd><p class="first last">Cost matrix of the classification problem
Where the columns represents the costs of: false positives, false negatives,
true positives and true negatives, for each example.</p>
</dd>
<dt>per: float, optional (default = 0.5)</dt>
<dd><p class="first last">Percentage of the minority class in the over-sampled data</p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r17" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[R17]</a></td><td>N. Chawla, K. Bowyer, L. Hall, W. Kegelmeyer, &#8220;SMOTE: Synthetic Minority Over-sampling Technique&#8221;,
Journal of Artificial Intelligence Research, 16, 321-357, 2002.</td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">costcla.datasets</span> <span class="kn">import</span> <span class="n">load_creditscoring1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">costcla.sampling</span> <span class="kn">import</span> <span class="n">smote</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_creditscoring1</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_smote</span><span class="p">,</span> <span class="n">target_smote</span> <span class="o">=</span> <span class="n">smote</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">per</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Size of each training set</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data_smote</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">112915 204307</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># Percentage of positives in each training set</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">target_smote</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="go">0.0674489660364 0.484604051746</span>
</pre></div>
</div>
</dd></dl>

</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="changelog.html" class="btn btn-neutral float-right" title="Change Log" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Probcal.html" class="btn btn-neutral" title="Probcal" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014, Alejandro Correa Bahnsen.
    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>