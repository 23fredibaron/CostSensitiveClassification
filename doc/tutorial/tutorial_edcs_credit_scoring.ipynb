{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example-Dependent Clasification for Credit Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  In order to mitigate the impact of credit risk and make more objective and accurate decisions, \n",
    "  financial institutions use credit scores to predict and control their losses.\n",
    "  The objective in credit scoring is to classify which potential customers are likely to default a \n",
    "  contracted financial obligation based on the customer's past financial experience, and with that \n",
    "  information decide whether to approve or decline a loan [1]. This tool has \n",
    "  become a standard practice among financial institutions around the world in order to predict \n",
    "  and control their loans portfolios. When constructing credit scores, it is a common practice to \n",
    "  use standard cost-insensitive binary classification algorithms such as logistic regression, \n",
    "  neural networks, discriminant analysis, genetic programing, decision trees, among \n",
    "  others [2,3]. \n",
    "  \n",
    "  Formally, a credit score is a statistical model that allows the estimation of the probability \n",
    "  $\\hat p_i=P(y_i=1|\\mathbf{x}_i)$ of a customer $i$ defaulting a contracted debt. Additionally, \n",
    "since the objective of credit scoring is to estimate a classifier $c_i$ to decide whether or not to grant a \n",
    "loan to a customer $i$, a threshold $t$ is defined such that if $\\hat p_i < t $, then the loan is \n",
    "  granted, i.e., $c_i(t)=0$, and denied otherwise, i.e., $c_i(t)=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Pacific-Asia Knowledge Discovery and Data Mining conference (PAKDD) competition 2009\n",
    "\n",
    "Credit Risk Assessment on a Private Label Credit Card Application\n",
    "\n",
    "### Load dataset and show basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target_names', 'cost_mat', 'name', 'DESCR', 'feature_names', 'data', 'target']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from costcla.datasets import load_creditscoring2\n",
    "data = load_creditscoring2()\n",
    "\n",
    "# Elements of the data file\n",
    "print data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full description of the dataset\n",
    "# print data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID_SHOP' 'AGE' 'AREA_CODE_RESIDENCIAL_PHONE' 'PAYMENT_DAY' 'SHOP_RANK'\n",
      " 'MONTHS_IN_RESIDENCE' 'MONTHS_IN_THE_JOB' 'PROFESSION_CODE' 'MATE_INCOME'\n",
      " 'QUANT_ADDITIONAL_CARDS_IN_THE_APPLICATION' 'PERSONAL_NET_INCOME' 'SEX_F'\n",
      " 'SEX_M' 'MARITAL_STATUS_C' 'MARITAL_STATUS_D' 'MARITAL_STATUS_O'\n",
      " 'MARITAL_STATUS_S' 'MARITAL_STATUS_V' 'FLAG_RESIDENCIAL_PHONE_N'\n",
      " 'FLAG_RESIDENCIAL_PHONE_Y' 'RESIDENCE_TYPE_A' 'RESIDENCE_TYPE_C'\n",
      " 'RESIDENCE_TYPE_O' 'RESIDENCE_TYPE_P' 'FLAG_MOTHERS_NAME_N'\n",
      " 'FLAG_MOTHERS_NAME_Y' 'FLAG_FATHERS_NAME_N' 'FLAG_FATHERS_NAME_Y'\n",
      " 'FLAG_RESIDENCE_TOWN_eq_WORKING_TOWN_N'\n",
      " 'FLAG_RESIDENCE_TOWN_eq_WORKING_TOWN_Y'\n",
      " 'FLAG_RESIDENCE_STATE_eq_WORKING_STATE_N'\n",
      " 'FLAG_RESIDENCE_STATE_eq_WORKING_STATE_Y'\n",
      " 'FLAG_RESIDENCIAL_ADDRESS_eq_POSTAL_ADDRESS_N'\n",
      " 'FLAG_RESIDENCIAL_ADDRESS_eq_POSTAL_ADDRESS_Y']\n",
      "(38938, 34)\n"
     ]
    }
   ],
   "source": [
    "# Number of features\n",
    "print data.feature_names\n",
    "print data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.8854589347\n"
     ]
    }
   ],
   "source": [
    "# Percentage of bad (positive) clients\n",
    "print data.target.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit scoring as a standard classification problem\n",
    "\n",
    "Using a three classifiers, a model is learned to classify customers in good and bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load classifiers and split dataset in training and testing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test, cost_mat_train, cost_mat_test = \\\n",
    "train_test_split(data.data, data.target, data.cost_mat)\n",
    "\n",
    "# Fit the classifiers using the training dataset\n",
    "classifiers = {\"RF\": {\"f\": RandomForestClassifier()},\n",
    "               \"DT\": {\"f\": DecisionTreeClassifier()},\n",
    "               \"LR\": {\"f\": LogisticRegression()}}\n",
    "\n",
    "for model in classifiers.keys():\n",
    "    # Fit\n",
    "    classifiers[model][\"f\"].fit(X_train, y_train)\n",
    "    # Predict\n",
    "    classifiers[model][\"c\"] = classifiers[model][\"f\"].predict(X_test)\n",
    "    classifiers[model][\"p\"] = classifiers[model][\"f\"].predict_proba(X_test)\n",
    "    classifiers[model][\"p_train\"] = classifiers[model][\"f\"].predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  After the classifier $c_i$ is estimated, there is a need to evaluate its performance. In \n",
    "  practice, many statistical evaluation measures are used to assess the performance of a credit \n",
    "  scoring model. Measures such as the area under the  receiver operating characteristic curve (AUC),\n",
    "  Brier score, Kolmogorov-Smirnoff (K-S) statistic,  $F_1$-Score, and misclassification are among \n",
    "  the most common [4]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pre        f1       acc       rec\n",
      "RF  0.374302  0.117595  0.793426  0.069755\n",
      "LR  0.466667  0.014352  0.802465  0.007288\n",
      "DT  0.245098  0.258430  0.690498  0.273295\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "measures = {\"f1\": f1_score, \"pre\": precision_score, \n",
    "            \"rec\": recall_score, \"acc\": accuracy_score}\n",
    "results = pd.DataFrame(columns=measures.keys())\n",
    "\n",
    "# Evaluate each model in classifiers\n",
    "for model in classifiers.keys():\n",
    "    results.loc[model] = [measures[measure](y_test, classifiers[model][\"c\"]) for measure in measures.keys()]\n",
    "\n",
    "# TODO: plot the results\n",
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Nevertheless, none of these measures takes into account the \n",
    "  business and economical realities that take place in credit scoring. Costs that the financial \n",
    "  institution had incurred to acquire customers, or the expected profit due to a particular client, \n",
    "  are not considered in the evaluation of the different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Evaluation of a Credit Scorecard\n",
    "\n",
    "  Typically, a credit risk model is evaluated using standard cost-insensitive measures.\n",
    "  However, in practice, the cost associated with approving \n",
    "  what is known as a bad customer, i.e., a customer who default his credit loan, is quite \n",
    "  different from the cost associated with declining a good customer,  i.e., a customer who \n",
    "  successfully repay his credit loan. Furthermore, the costs are not constant among customers. \n",
    "  This is because loans have different credit line amounts, terms, and even interest rates. Some \n",
    "  authors have proposed methods that include the misclassification costs in the credit scoring \n",
    "  context [4,5,6,7].\n",
    "  \n",
    "  In order to take into account the varying costs that each example carries, we proposed in \n",
    "  [8], a cost matrix with example-dependent misclassification costs as \n",
    "  given in the following table.\n",
    "  \n",
    "  \n",
    "|  \t| Actual Positive ($y_i=1$)  \t|  Actual Negative \t($y_i=0$)|\n",
    "|---\t|:-:\t|:-:\t|\n",
    "|   Predicted Positive ($c_i=1$)\t|   $C_{TP_i}=0$\t|  $C_{FP_i}=r_i+C^a_{FP}$ \t|\n",
    "|  Predicted Negative  ($c_i=0$) \t|   $C_{FN_i}=Cl_i \\cdot L_{gd}$\t| $C_{TN_i}=0$\t|\n",
    "  \n",
    "  First, we assume that the costs of a correct \n",
    "  classification, $C_{TP_i}$ and $C_{TN_i}$, are zero for every customer $i$. We define $C_{FN_i}$ \n",
    "  to be the losses if the customer $i$ defaults to be proportional to his credit line $Cl_i$. We \n",
    "  define the cost of a false positive per customer $C_{FP_i}$ as the sum of two real financial \n",
    "  costs $r_i$ and $C^a_{FP}$, where $r_i$ is the loss in profit by rejecting what would have been a \n",
    "  good customer. \n",
    "  \n",
    "  The profit per customer $r_i$ is calculated as the present value of the difference between the \n",
    "  financial institution gains and expenses, given the credit line $Cl_i$, the term $l_i$ and the \n",
    "  financial institution lending rate $int_{r_i}$ for customer $i$, and the financial institution \n",
    "  of cost funds $int_{cf}$.\n",
    "\n",
    "  $$  r_i= PV(A(Cl_i,int_{r_i},l_i),int_{cf},l_i)-Cl_i,$$\n",
    "  \n",
    "  with $A$ being the customer monthly payment and $PV$ the present value of the monthly payments,\n",
    "  which are calculated using the time value of money equations [9],\n",
    " \n",
    " $$ A(Cl_i,int_{r_i},l_i) =  Cl_i \\frac{int_{r_i}(1+int_{r_i})^{l_i}}{(1+int_{r_i})^{l_i}-1},$$\n",
    " \n",
    " $$ PV(A,int_{cf},l_i) = \\frac{A}{int_{cf}} \\left(1-\\frac{1}{(1+int_{cf})^{l_i}} \\right).$$\n",
    "      \n",
    "  The second term $C^a_{FP}$, is related to the assumption that the financial institution will not \n",
    "  keep the money of the declined customer idle. It will instead give a loan to an alternative \n",
    "  customer [10]. Since no further information is known about the alternative customer, \n",
    "  it is assumed to have an average credit line $\\overline{Cl}$ and an average profit $\\overline{r}$.\n",
    "  Given that, \n",
    "  \n",
    "  $$  C^a_{FP}=- \\overline{r} \\cdot \\pi_0+\\overline{Cl}\\cdot L_{gd} \\cdot \\pi_1,$$\n",
    "\n",
    "  in other words minus the profit of an average alternative customer plus the expected loss, \n",
    "  taking into account that the alternative customer will pay his debt with a probability equal to \n",
    "  the prior negative rate, and similarly will default with probability equal to the prior positive \n",
    "  rate.\n",
    "  \n",
    "  One key parameter of our model is the credit limit. There exists several strategies to calculate \n",
    "  the $Cl_i$ depending on the type of loans, the state of the economy, the current portfolio, \n",
    "  among others [1,9]. Nevertheless, given the lack of information \n",
    "  regarding the specific business environments of the considered datasets, we simply define \n",
    "  $Cl_i$ as\n",
    "\n",
    "$$      Cl_i = \\min \\bigg\\{ q \\cdot Inc_i, Cl_{max}, Cl_{max}(debt_i) \\bigg\\},$$\n",
    "  \n",
    "  where $Inc_i$ and $debt_i$ are the monthly income and debt ratio of the customer $i$, \n",
    "  respectively, $q$ is a parameter that defines the maximum $Cl_i$ in times $Inc_i$, and \n",
    "  $Cl_{max}$ the maximum overall credit line. Lastly, the maximum credit line given the current \n",
    "  debt is calculated as the maximum credit limit such that the current debt ratio plus the new \n",
    "  monthly payment does not surpass the customer monthly income. It is calculated as\n",
    " \n",
    " $$  Cl_{max}(debt_i)=PV\\left(Inc_i \\cdot P_{m}(debt_i),int_{r_i},l_i\\right),$$\n",
    "  and\n",
    "  $$ P_{m}(debt_i)=\\min \\left\\{ \\frac{A(q \\cdot Inc_i,int_{r_i},l_i)}{Inc_i},\\left(1-debt_i \\right) \\right\\}.$$\n",
    "  \n",
    "  \n",
    "### Financial savings\n",
    "\n",
    "  Let $\\mathcal{S}$ be a set of $N$ examples $i$, $N=\\vert S \\vert$, where each example is \n",
    "  represented by  the augmented feature vector \n",
    "  $\\mathbf{x}_i^*=[\\mathbf{x}_i, C_{TP_i},C_{FP_i},C_{FN_i},C_{TN_i}]$  \n",
    "  and labeled using the class   label $y_i   \\in \\{0,1\\}$. \n",
    "  A classifier $f$ which generates the   predicted label $c_i$ for each   element $i$ is trained  \n",
    "  using the set $\\mathcal{S}$. Then the cost of   using $f$ on $\\mathcal{S}$ is calculated by\n",
    "  \n",
    "  $$   Cost(f(\\mathcal{S})) = \\sum_{i=1}^N Cost(f(\\mathbf{x}_i^*)),$$\n",
    "  \n",
    "  where\n",
    "  \n",
    " $$   Cost(f(\\mathbf{x}_i^*)) = y_i(c_i C_{TP_i} + (1-c_i)C_{FN_i}) + (1-y_i)(c_i C_{FP_i} + (1-c_i)C_{TN_i}).$$\n",
    "  \n",
    "\n",
    "  However, the total cost may not be easy to interpret. We proposed an approach in [8], where the savings of using an algorithm  are defined as the cost of the algorithm versus the cost of using no algorithm at all.  To do that, the cost of the costless class is defined as \n",
    "  \n",
    "  $$  Cost_l(\\mathcal{S}) = \\min \\{Cost(f_0(\\mathcal{S})), Cost(f_1(\\mathcal{S}))\\},$$\n",
    "  \n",
    "  where \n",
    "  \n",
    "  $$  f_a(\\mathcal{S}) = \\mathbf{a}, \\text{ with } a\\in \\{0,1\\}.$$\n",
    "  \n",
    "\n",
    "  The cost improvement can be expressed as the cost savings as compared with $Cost_l(\\mathcal{S})$. \n",
    "  \n",
    "  $$    Savings(f(\\mathcal{S})) = \\frac{ Cost_l(\\mathcal{S}) - Cost(f(\\mathcal{S}))}   {Cost_l(\\mathcal{S})}.$$\n",
    "  \n",
    "\n",
    "\n",
    "  ### Parameters for the PAKDD Credit Database\n",
    "\n",
    " As this database contain information regarding the features, and more importantly about the income of each example, from which an estimated credit limit $Cl_i$ can be calculated.\n",
    "Since no specific information regarding the datasets is provided, we assume that they belong to \n",
    "average Brazilian financial institution. This enabled us to find the different \n",
    "parameters needed to calculate the cost measure. \n",
    "\n",
    "| Parameter \t| Value |\n",
    "|---\t|:-:\t|\n",
    "|Interest rate ($int_r$) | 63.0% |\n",
    "|  Cost of funds ($int_{cf}$) | 16.5% |\n",
    "|  Term ($l$) in months | 24 |\n",
    "|  Loss given default ($L_{gd}$) | 75% |\n",
    "|  Times income ($q$) | 3 |\n",
    "|  Maximum credit line ($Cl_{max}$) | 25,000|\n",
    "\n",
    "In particular, we obtain the average interest rates in Brazil during 2004 from Trading Economics [11]. Moreover, we convert all monetary values to Euros. Additionally, we use a fixed loan term $l$, \n",
    "because the PAKDD Credit dataset is related to credit cards the term is fix to two years [9].\n",
    "Moreover, we set the loss given default $L_{gd}$ using information from \n",
    "the Basel II standard, $q$ to 3 since it is the average personal loan requests related to monthly income, and the maximum credit limit $Cl_{max}$ to 25,000 Euros.\n",
    "\n",
    "### Calculation of the savings of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 209.     547.965    0.       0.   ]\n",
      " [  24.     274.725    0.       0.   ]\n",
      " [  89.     371.25     0.       0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# The cost matrix is already calculated for the dataset\n",
    "# cost_mat[C_FP,C_FN,C_TP,C_TN]\n",
    "print data.cost_mat[[10, 17, 50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pre        f1       acc       rec       sav\n",
      "RF  0.374302  0.117595  0.793426  0.069755  0.033327\n",
      "LR  0.466667  0.014352  0.802465  0.007288  0.003709\n",
      "DT  0.245098  0.258430  0.690498  0.273295 -0.039801\n"
     ]
    }
   ],
   "source": [
    "# Calculation of the cost and savings\n",
    "from costcla.metrics import savings_score, cost_loss \n",
    "\n",
    "# Evaluate the savings for each model\n",
    "results[\"sav\"] = np.zeros(results.shape[0])\n",
    "for model in classifiers.keys():\n",
    "    results[\"sav\"].loc[model] = savings_score(y_test, classifiers[model][\"c\"], cost_mat_test)\n",
    "\n",
    "# TODO: plot results\n",
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite interesting how the model is not making significant savings, as the cost of using this model is almost equal to the cost of predicting all the examples as negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model  760323.437775\n",
      "RF model  734984.442775\n"
     ]
    }
   ],
   "source": [
    "print \"No model \", cost_loss(y_test, np.zeros(y_test.shape), cost_mat_test)\n",
    "print \"RF model \", cost_loss(y_test, classifiers[\"RF\"][\"c\"], cost_mat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we found significant differences in the \n",
    "results when evaluating a model using a  traditional cost-insensitive measure such as the \n",
    "accuracy or F1Score,  than when using the savings, leading to the conclusion of the \n",
    "importance of using the real practical financial costs of each context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization\n",
    "\n",
    "TODO: fill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF-THO  0.318181818182\n",
      "LR-THO  0.212121212121\n",
      "DT-THO  0.750355956336\n",
      "             pre        f1       acc       rec       sav\n",
      "RF      0.374302  0.117595  0.793426  0.069755  0.033327\n",
      "LR      0.466667  0.014352  0.802465  0.007288  0.003709\n",
      "DT      0.245098  0.258430  0.690498  0.273295 -0.039801\n",
      "RF-BMR  0.231037  0.346134  0.485773  0.689745  0.306838\n",
      "LR-BMR  0.236960  0.356433  0.487725  0.718896  0.325230\n",
      "DT-BMR  0.220248  0.330872  0.469440  0.664758  0.273746\n",
      "RF-THO  0.349576  0.232722  0.776477  0.174419  0.072666\n",
      "LR-THO  0.305771  0.401019  0.661839  0.582452  0.231622\n",
      "DT-THO  0.000000  0.000000  0.805650  0.000000  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from costcla.models import ThresholdingOptimization\n",
    "ci_models = classifiers.keys()\n",
    "\n",
    "for model in ci_models:\n",
    "    classifiers[model+\"-THO\"] = {\"f\": ThresholdingOptimization()}\n",
    "    # Fit\n",
    "    classifiers[model+\"-THO\"][\"f\"].fit(classifiers[model][\"p\"], cost_mat_test, y_test)\n",
    "    print model+\"-THO \", classifiers[model+\"-THO\"][\"f\"].threshold_\n",
    "    # Predict\n",
    "    classifiers[model+\"-THO\"][\"c\"] = classifiers[model+\"-THO\"][\"f\"].predict(classifiers[model][\"p\"])\n",
    "    # Evaluate\n",
    "    results.loc[model+\"-THO\"] = 0\n",
    "    results.loc[model+\"-THO\", measures.keys()] = \\\n",
    "    [measures[measure](y_test, classifiers[model+\"-THO\"][\"c\"]) for measure in measures.keys()]\n",
    "    results[\"sav\"].loc[model+\"-THO\"] = savings_score(y_test, classifiers[model+\"-THO\"][\"c\"], cost_mat_test)\n",
    "\n",
    "# TODO: Plot results\n",
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes minimum risk\n",
    "\n",
    "As these methods (RF, LR and DT) are not performing well we then move to use cost-sensitive methods. The first model we used is the Bayes minimum risk model (BMR) [8].\n",
    "\n",
    "As defined in [12], the BMR classifier is a decision model based on quantifying \n",
    "tradeoffs between various decisions using probabilities and the costs that accompany such decisions. \n",
    "This is done in a way that for each example the expected losses are minimized. In  what follows, we \n",
    "consider the probability estimates $\\hat p_i$ as known, regardless of the algorithm used to \n",
    "calculate them.  The risk that accompanies each decision is calculated using the cost matrix described above.\n",
    "In the specific framework of binary classification, the risk of predicting the example $i$ as negative is \n",
    "\n",
    "$$ R(c_i=0|\\mathbf{x}_i)=C_{TN_i}(1-\\hat p_i)+C_{FN_i} \\cdot \\hat p_i, $$\n",
    "and\n",
    "$$ R(c_i=1|\\mathbf{x}_i)=C_{TP_i} \\cdot \\hat p_i + C_{FP_i}(1- \\hat p_i), $$\n",
    "\n",
    "is the risk when predicting the example as positive, where $\\hat p_i$ is the estimated positive \n",
    "probability for example $i$. Subsequently, if \n",
    "\n",
    "$$  R(c_i=0|\\mathbf{x}_i) \\le R(c_i=1|\\mathbf{x}_i), $$\n",
    "\n",
    "then  the example $i$ is classified as negative. This means that the risk associated with the \n",
    "decision $c_i$ is lower than the risk associated with classifying it as positive. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pre        f1       acc       rec       sav\n",
      "RF      0.374302  0.117595  0.793426  0.069755  0.033327\n",
      "LR      0.466667  0.014352  0.802465  0.007288  0.003709\n",
      "DT      0.245098  0.258430  0.690498  0.273295 -0.039801\n",
      "RF-BMR  0.231649  0.347551  0.492450  0.695560  0.292156\n",
      "LR-BMR  0.239270  0.360141  0.497381  0.727801  0.322408\n",
      "DT-BMR  0.223376  0.335138  0.482794  0.670719  0.285939\n",
      "RF-THO  0.349576  0.232722  0.776477  0.174419  0.072666\n",
      "LR-THO  0.305771  0.401019  0.661839  0.582452  0.231622\n",
      "DT-THO  0.000000  0.000000  0.805650  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "from costcla.models import BayesMinimumRiskClassifier\n",
    "\n",
    "for model in ci_models:\n",
    "    classifiers[model+\"-BMR\"] = {\"f\": BayesMinimumRiskClassifier()}\n",
    "    # Fit\n",
    "    classifiers[model+\"-BMR\"][\"f\"].fit(y_test, classifiers[model][\"p\"])\n",
    "    # Predict\n",
    "    classifiers[model+\"-BMR\"][\"c\"] = classifiers[model+\"-BMR\"][\"f\"].predict(classifiers[model][\"p\"], cost_mat_test)\n",
    "    # Evaluate\n",
    "    results.loc[model+\"-BMR\"] = 0\n",
    "    results.loc[model+\"-BMR\", measures.keys()] = \\\n",
    "    [measures[measure](y_test, classifiers[model+\"-BMR\"][\"c\"]) for measure in measures.keys()]\n",
    "    results[\"sav\"].loc[model+\"-BMR\"] = savings_score(y_test, classifiers[model+\"-BMR\"][\"c\"], cost_mat_test)\n",
    "    \n",
    "# TODO: Plot results\n",
    "print results\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-sensitive decision trees\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pre        f1       acc       rec       sav\n",
      "RF      0.374302  0.117595  0.793426  0.069755  0.033327\n",
      "LR      0.466667  0.014352  0.802465  0.007288  0.003709\n",
      "DT      0.245098  0.258430  0.690498  0.273295 -0.039801\n",
      "RF-BMR  0.231649  0.347551  0.492450  0.695560  0.292156\n",
      "LR-BMR  0.239270  0.360141  0.497381  0.727801  0.322408\n",
      "DT-BMR  0.223376  0.335138  0.482794  0.670719  0.285939\n",
      "RF-THO  0.349576  0.232722  0.776477  0.174419  0.072666\n",
      "LR-THO  0.305771  0.401019  0.661839  0.582452  0.231622\n",
      "DT-THO  0.000000  0.000000  0.805650  0.000000  0.000000\n",
      "CSDT    0.223735  0.339498  0.468002  0.703488  0.294629\n"
     ]
    }
   ],
   "source": [
    "from costcla.models import CostSensitiveDecisionTreeClassifier\n",
    "\n",
    "classifiers[\"CSDT\"] = {\"f\": CostSensitiveDecisionTreeClassifier()}\n",
    "# Fit\n",
    "classifiers[\"CSDT\"][\"f\"].fit(X_train, y_train, cost_mat_train)\n",
    "# Predict\n",
    "classifiers[\"CSDT\"][\"c\"] = classifiers[\"CSDT\"][\"f\"].predict(X_test)\n",
    "# Evaluate\n",
    "results.loc[\"CSDT\"] = 0\n",
    "results.loc[\"CSDT\", measures.keys()] = \\\n",
    "[measures[measure](y_test, classifiers[\"CSDT\"][\"c\"]) for measure in measures.keys()]\n",
    "results[\"sav\"].loc[\"CSDT\"] = savings_score(y_test, classifiers[\"CSDT\"][\"c\"], cost_mat_test)\n",
    "    \n",
    "# TODO: Plot results\n",
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. ~\\citep{Anderson2007}\n",
    "2. ~\\citep{Hand1997}\n",
    "3. ~\\citep{Bahnsen2011}\n",
    "4. \\citep{Beling2005}\n",
    "5. \\citep{Verbraken2014\n",
    "6.  Alejo2013\n",
    "7.  Oliver2009}.\n",
    "8.  \\citep{CorreaBahnsen2014b}\n",
    "9.  \\citep{Lawrence2012}\n",
    "10. \\citep{Nayak1997}\n",
    "11. \\citep{Economics2014}\n",
    "12. \\citep{Ghosh2006}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
